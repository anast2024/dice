/*
 * Copyright (C) Huawei Technologies Co., Ltd. 2023-2025. All rights reserved.
 * SPDX-License-Identifier: MIT
 */
/*******************************************************************************
 * @file tsan.c
 * @brief Implements a TSAN interface that publishes events.
 *
 ******************************************************************************/
#include <stdint.h>
#include <bingo/module.h>
#include <bingo/intercept.h>
#include <bingo/memaccess.h>

BINGO_MODULE_INIT()

#define _tmpl_mute // ----------- simple empty macros to make clangd happy -----
#define _tmpl_map(...)
#define _tmpl_begin(...)
#define _tmpl_end(...)
#define __atomic_fetch_OP __atomic_exchange_n
#define uintBITS_t int
#define PARAM_SUF  0
#define EV_TYPE(...) 0
#define UPCASE
#define SZ 0
#define FUNC
#define BITS 0
#define _tmpl_unmute // --------------------------------------------------------
_tmpl_map(nix,)
_tmpl_map(UPCASE,_tmpl_upcase)
_tmpl_map(EV_TYPE, EVENT_MA_UPCASE)
_tmpl_map(PARAM_strong, 0)
_tmpl_map(PARAM_weak, 1)

void __tsan_init() {}
void __tsan_write_range(void) {}
void __tsan_read_range(void) {}
void __tsan_vptr_read(void **vptr_p) {}
void __tsan_vptr_update(void **vptr_p, void *new_val) {}

/* with GCC version < 10, this symbols is defined */
void internal_sigreturn(void) {}

void __tsan_mutex_pre_lock(void *addr, unsigned flags) {}
void __tsan_mutex_post_lock(void *addr, unsigned flags, int recursion) {}
int __tsan_mutex_pre_unlock(void *addr, unsigned flags) { return 0; }
void __tsan_mutex_post_unlock(void *addr, unsigned flags) {}
void __tsan_mutex_create(void *addr, unsigned flags) {}
void __tsan_mutex_destroy(void *addr, unsigned flags) {}
void __tsan_acquire(void *addr) {}
void __tsan_release(void *addr) {}
void __tsan_func_entry(void *pc) {}
void __tsan_func_exit(void) {}

/* plain reads and writes */
_tmpl_begin(PFX=[[nix;unaligned_]], FUNC=[[read;write]], SZ=[[1;2;4;8;16]])
void
__tsan_PFXFUNCSZ(void *a)
{

    memaccess_t ma = {.pc      = 0,
                      .func    = "PFXFUNCSZ",
                      .addr    = (uintptr_t) a,
                      .size    = SZ,
                      0};
    intercept_at(EV_TYPE(FUNC), &ma, 0);
}
_tmpl_end()

/* plain reads and writes 2 values */
_tmpl_begin(FUNC=[[read;write]], SZ=[[1;2;4;8;16]])
void
__tsan_FUNCSZ_pc(void *a, void *b)
{
    intercept_at(EV_TYPE(FUNC), 0, 0);
}
_tmpl_end()

/* atomic loads */
_tmpl_begin(BITS=[[8;16;32;64]])
uintBITS_t
__tsan_atomicBITS_load(const volatile uintBITS_t *a, int mo)
{
    (void) mo;
    memaccess_t ma = {.pc      = 0,
                      .func    = "atomicBITS_load",
                      .addr    = (uintptr_t) a,
                      .size    = (BITS>>3),
                      0};
    intercept_before(EV_TYPE(AREAD), &ma, 0);
    uintBITS_t r = __atomic_load_n(a, __ATOMIC_SEQ_CST);
    ma.argu128 = (__uint128_t) r;
    intercept_after(EV_TYPE(AREAD), &ma, 0);
    return r;
}
_tmpl_end()

/* atomic stores */
_tmpl_begin(BITS=[[8;16;32;64]])
void
__tsan_atomicBITS_store(volatile uintBITS_t *a, uintBITS_t v, int mo)
{
    (void) mo;
    memaccess_t ma = {.pc      = 0,
                      .func    = "atomicBITS_store",
                      .addr    = (uintptr_t) a,
                      .size    = (BITS>>3),
                      .argu128 = (__uint128_t) v,
                      0};
    intercept_before(EV_TYPE(AWRITE), &ma, 0);
    __atomic_store_n(a, v, __ATOMIC_SEQ_CST);
    intercept_after(EV_TYPE(AWRITE), &ma, 0);
}
_tmpl_end()


/* xchg */
_tmpl_begin(BITS=[[8;16;32;64]])
uintBITS_t
__tsan_atomicBITS_exchange(volatile uintBITS_t *a, uintBITS_t v, int mo)
{
    (void) mo;
    memaccess_t ma = {.pc      = 0,
                      .func    = "atomicBITS_exchange",
                      .addr    = (uintptr_t) a,
                      .size    = (BITS>>3),
                      .argu128 = (__uint128_t) v,
                      0};
    intercept_before(EV_TYPE(XCHG), &ma, 0);
    uintBITS_t r = __atomic_exchange_n(a, v, __ATOMIC_SEQ_CST);
    ma.argu128 = (__uint128_t) r;
    intercept_after(EV_TYPE(XCHG), &ma, 0);
    return r;
}
_tmpl_end()

/* fetch_RMW */
_tmpl_begin(OP=[[add;sub;and;or;xor;nand]], BITS=[[8;16;32;64]])
uintBITS_t
__tsan_atomicBITS_fetch_OP(volatile uintBITS_t *a, uintBITS_t v, int mo)
{
    (void) mo;
    memaccess_t ma = {.pc      = 0,
                      .func    = "atomicBITS_fetch_OP",
                      .addr    = (uintptr_t) a,
                      .size    = (BITS>>3),
                      .argu128 = (__uint128_t) v,
                      0};
    intercept_before(EV_TYPE(RMW), &ma, 0);
    uintBITS_t r = __atomic_fetch_OP(a, v, __ATOMIC_SEQ_CST);
    ma.argu128 = (__uint128_t) r;
    intercept_after(EV_TYPE(RMW), &ma, 0);
    return r;
}
_tmpl_end()


/* compare_exchange_{strong,weak} */
_tmpl_begin(SUF=[[strong;weak]], BITS=[[8;16;32;64]])
int
__tsan_atomicBITS_compare_exchange_SUF(volatile uintBITS_t *a, uintBITS_t *c, uintBITS_t v, int mo)
{
    memaccess_t ma = {.pc      = 0,
                      .func    = "atomicBITS_compare_exchange_SUF",
                      .addr    = (uintptr_t) a,
                      .size    = (BITS>>3),
                      .argu128 = (__uint128_t) v,
                      0};
    intercept_before(EV_TYPE(CMPXCHG), &ma, 0);
    int r = __atomic_compare_exchange_n(a, c, v, PARAM_SUF, __ATOMIC_SEQ_CST, __ATOMIC_SEQ_CST);
    intercept_after(EV_TYPE(CMPXCHG), 0, 0);
    return r;
}
_tmpl_end()

/* compare_exchange_val */
_tmpl_begin(BITS=[[8;16;32;64]])
uintBITS_t
__tsan_atomicBITS_compare_exchange_val(volatile uintBITS_t *a, uintBITS_t c, uintBITS_t v, int mo)
{
    memaccess_t ma = {.pc      = 0,
                      .func    = "atomicBITS_compare_exchange_val",
                      .addr    = (uintptr_t) a,
                      .size    = (BITS>>3),
                      .argu128 = (__uint128_t) v,
                      0};
    intercept_before(EV_TYPE(CMPXCHG), &ma, 0);
    (void)__atomic_compare_exchange_n(a, &c, v, 0, __ATOMIC_SEQ_CST, __ATOMIC_SEQ_CST);
    intercept_after(EV_TYPE(CMPXCHG), 0, 0);
    return c;
}
_tmpl_end()

/* atomic fences */
void
__tsan_atomic_thread_fence(int  mo)
{
    (void) mo;
    intercept_before(EVENT_MA_FENCE, 0, 0);
    __atomic_thread_fence(__ATOMIC_SEQ_CST);
    intercept_after(EVENT_MA_FENCE, 0, 0);
}

void
__tsan_atomic_signal_fence(int mo)
{
    (void) mo;
    intercept_before(EVENT_MA_FENCE, 0, 0);
    __atomic_signal_fence(__ATOMIC_SEQ_CST);
    intercept_after(EVENT_MA_FENCE, 0, 0);
}
